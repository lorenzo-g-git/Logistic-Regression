# -*- coding: utf-8 -*-
"""Logistic regression +plot#1

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1U2XgNXrSkT2vhhcUHwiBhiX5Us3Vkk6Y

**Librerie**
"""

# importo le librerie per logistic regression e parte grafica
import matplotlib.pyplot as plt
import numpy as np
#importo i modelli utili 
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix

"""**Caricamento dei dati**"""

# creo dei vettori di dati: le righe corrispondono al numero di osservazioni; le colonne agli input
x = np.arange(10).reshape(-1, 1)
y = np.array([0, 0, 0, 0, 1, 1, 1, 1, 1, 1])

"""**Creazione del modello**"""

# creo un modello di regressione logistica standard
model = LogisticRegression(solver='liblinear', random_state=0)

#penalty is a string ('l2' by default) that decides whether there is regularization and which approach to use. Other options are 'l1', 'elasticnet', and 'none'.

#dual is a Boolean (False by default) that decides whether to use primal (when False) or dual formulation (when True).

#tol is a floating-point number (0.0001 by default) that defines the tolerance for stopping the procedure.

#C is a positive floating-point number (1.0 by default) that defines the relative strength of regularization. Smaller values indicate stronger regularization.

#fit_intercept is a Boolean (True by default) that decides whether to calculate the intercept ùëè‚ÇÄ (when True) or consider it equal to zero (when False).

#intercept_scaling is a floating-point number (1.0 by default) that defines the scaling of the intercept ùëè‚ÇÄ.

#class_weight is a dictionary, 'balanced', or None (default) that defines the weights related to each class. When None, all classes have the weight one.

#random_state is an integer, an instance of numpy.RandomState, or None (default) that defines what pseudo-random number generator to use.

#solver is a string ('liblinear' by default) that decides what solver to use for fitting the model. Other options are 'newton-cg', 'lbfgs', 'sag', and 'saga'.

#max_iter is an integer (100 by default) that defines the maximum number of iterations by the solver during model fitting.

#multi_class is a string ('ovr' by default) that decides the approach to use for handling multiple classes. Other options are 'multinomial' and 'auto'.

#verbose is a non-negative integer (0 by default) that defines the verbosity for the 'liblinear' and 'lbfgs' solvers.

#warm_start is a Boolean (False by default) that decides whether to reuse the previously obtained solution.

#n_jobs is an integer or None (default) that defines the number of parallel processes to use. None usually means to use one core, while -1 means to use all available cores.

#l1_ratio is either a floating-point number between zero and one or None (default). It defines the relative importance of the L1 part in the elastic-net regularization.

#liblinear' solver doesn‚Äôt work without regularization.
#'newton-cg', 'sag', 'saga', and 'lbfgs' don‚Äôt support L1 regularization.
#'saga' is the only solver that supports elastic-net regularization.

#fit() takes x, y, and possibly observation-related weights. Then it fits the model and returns the model instance itself:
model.fit(x, y)

#posso concatenare  il modello e la funzione fit
model = LogisticRegression(solver='liblinear', random_state=0).fit(x, y)

# voglio sapere i valori di intercetta e baias
model.intercept_

model.coef_

"""**Valutazione del modello**"""

# mi vedo la probabilit√† di previsone corretta del mio modello
model.predict_proba(x)

# i valor predetti corrispondenti sono
model.predict(x)

# per valutare il mio modello posso usare uno score (#predizioni corrette/ #osservazioni
model.score(x, y)

"""**Confusion Matrix**"""

# per avere pi√π informazioni sul mio modello posso usare una Confusion matrix.
# dal punto di vista matematico, per una classificazione binaria , quello che avr√≤ sar√†:
# #Reali negativi #Falso positivo
# #Falsi negativi #Rerale positivo

confusion_matrix(y, model.predict(x))

# posso plottare un grafico colorato della confusion matrix ( carino per la parte estetica)
# colori differenti per nuemeri differenti , colori simili per numeri simili
cm = confusion_matrix(y, model.predict(x))

fig, ax = plt.subplots(figsize=(8, 8))
ax.imshow(cm)
ax.grid(False)
ax.xaxis.set(ticks=(0, 1), ticklabels=('Predicted 0s', 'Predicted 1s'))
ax.yaxis.set(ticks=(0, 1), ticklabels=('Actual 0s', 'Actual 1s'))
ax.set_ylim(1.5, -0.5)
for i in range(2):
    for j in range(2):
        ax.text(j, i, cm[i, j], ha='center', va='center', color='red')
plt.show()

# posso stamparmi un resoconto finale del modello grazie la funzione report()
print(classification_report(y, model.predict(x)))